{"id":"60bd1dcb-be4f-486a-ab72-9227d7991edf","data":{"nodes":[{"id":"TextInput-lzJYa","type":"genericNode","position":{"x":-345.42535258051726,"y":291.7868636693585},"data":{"type":"TextInput","node":{"template":{"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"LLM","fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Record","Text"],"dynamic":false,"info":"Text or Record to be passed as input.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Text\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["object","str","Text"],"display_name":"Name","documentation":"","custom_fields":{"input_value":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"TextInput-lzJYa"},"selected":false,"width":384,"height":297,"positionAbsolute":{"x":-345.42535258051726,"y":291.7868636693585},"dragging":false},{"id":"Prompt-Ts5jb","type":"genericNode","position":{"x":1357.7126619230237,"y":-367.1075946283439},"data":{"type":"Prompt","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import CustomComponent\nfrom langflow.field_typing import TemplateField\nfrom langflow.field_typing.prompt import Prompt\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    async def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Prompt:\n        prompt = await Prompt.from_template_and_variables(template, kwargs)\n        self.status = prompt.format_text()\n        return prompt\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"prompt","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"Hey, answer the users question based on the following context:\n\nThe context is this: {context}\n\nAnd this is the message history: {history}\n\nThe users question is this: {question}]\n\n","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent","context":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"context","display_name":"context","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"history":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"history","display_name":"history","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"question":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"question","display_name":"question","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Prompt","Record"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["context","history","question"]},"output_types":["Prompt"],"full_path":null,"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"error":null},"id":"Prompt-Ts5jb","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":607,"positionAbsolute":{"x":1357.7126619230237,"y":-367.1075946283439},"dragging":false},{"id":"ChatInput-nCUEa","type":"genericNode","position":{"x":270.57892238325894,"y":172.5338794097836},"data":{"type":"ChatInput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.schema.message import Message\nfrom langflow.field_typing import Text\nfrom typing import Union\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    def build_config(self):\n        build_config = super().build_config()\n        build_config[\"input_value\"] = {\n            \"input_types\": [],\n            \"display_name\": \"Text\",\n            \"multiline\": True,\n        }\n\n        return build_config\n\n    def build(\n        self,\n        sender: Optional[str] = \"User\",\n        sender_name: Optional[str] = \"User\",\n        input_value: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        session_id: Optional[str] = None,\n        return_message: Optional[bool] = False,\n    ) -> Union[Message, Text]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            files=files,\n            session_id=session_id,\n            return_message=return_message,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":[],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"value":"Und die Mail von Kathy Hill?"},"return_message":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_message","display_name":"Return Message","advanced":true,"dynamic":false,"info":"Return the message as a Message containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["Message","object","str","Text"],"display_name":"Chat Input","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"files":null,"session_id":null,"return_message":null},"output_types":["Message","Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatInput-nCUEa"},"selected":false,"width":384,"height":383,"positionAbsolute":{"x":270.57892238325894,"y":172.5338794097836},"dragging":false},{"id":"MemoryComponent-9ROme","type":"genericNode","position":{"x":261.78231532585994,"y":693.4279514516769},"data":{"type":"MemoryComponent","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.memory.memory import BaseMemoryComponent\nfrom langflow.field_typing import Text\nfrom langflow.helpers.record import messages_to_text\nfrom langflow.memory import get_messages\nfrom langflow.schema.message import Message\n\n\nclass MemoryComponent(BaseMemoryComponent):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages given a specific Session ID.\"\n    beta: bool = True\n    icon = \"history\"\n\n    def build_config(self):\n        return {\n            \"sender\": {\n                \"options\": [\"Machine\", \"User\", \"Machine and User\"],\n                \"display_name\": \"Sender Type\",\n            },\n            \"sender_name\": {\"display_name\": \"Sender Name\", \"advanced\": True},\n            \"n_messages\": {\n                \"display_name\": \"Number of Messages\",\n                \"info\": \"Number of messages to retrieve.\",\n            },\n            \"session_id\": {\n                \"display_name\": \"Session ID\",\n                \"info\": \"Session ID of the chat history.\",\n                \"input_types\": [\"Text\"],\n            },\n            \"order\": {\n                \"options\": [\"Ascending\", \"Descending\"],\n                \"display_name\": \"Order\",\n                \"info\": \"Order of the messages.\",\n                \"advanced\": True,\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def get_messages(self, **kwargs) -> list[Message]:\n        # Validate kwargs by checking if it contains the correct keys\n        if \"sender\" not in kwargs:\n            kwargs[\"sender\"] = None\n        if \"sender_name\" not in kwargs:\n            kwargs[\"sender_name\"] = None\n        if \"session_id\" not in kwargs:\n            kwargs[\"session_id\"] = None\n        if \"limit\" not in kwargs:\n            kwargs[\"limit\"] = 5\n        if \"order\" not in kwargs:\n            kwargs[\"order\"] = \"Descending\"\n\n        kwargs[\"order\"] = \"DESC\" if kwargs[\"order\"] == \"Descending\" else \"ASC\"\n        if kwargs[\"sender\"] == \"Machine and User\":\n            kwargs[\"sender\"] = None\n        return get_messages(**kwargs)\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine and User\",\n        sender_name: Optional[str] = None,\n        session_id: Optional[str] = None,\n        n_messages: int = 5,\n        order: Optional[str] = \"Descending\",\n        record_template: Optional[str] = \"{sender_name}: {text}\",\n    ) -> Text:\n        messages = self.get_messages(\n            sender=sender,\n            sender_name=sender_name,\n            session_id=session_id,\n            limit=n_messages,\n            order=order,\n        )\n        messages_str = messages_to_text(template=record_template or \"\", messages=messages)\n        self.status = messages_str\n        return messages_str\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"n_messages":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":5,"fileTypes":[],"file_path":"","password":false,"name":"n_messages","display_name":"Number of Messages","advanced":false,"dynamic":false,"info":"Number of messages to retrieve.","load_from_db":false,"title_case":false},"order":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Descending","fileTypes":[],"file_path":"","password":false,"options":["Ascending","Descending"],"name":"order","display_name":"Order","advanced":true,"dynamic":false,"info":"Order of the messages.","load_from_db":false,"title_case":false,"input_types":["Text"]},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"{sender_name}: {text}","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine and User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User","Machine and User"],"name":"sender","display_name":"Sender Type","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":false,"input_types":["Text"],"dynamic":false,"info":"Session ID of the chat history.","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Retrieves stored chat messages given a specific Session ID.","icon":"history","base_classes":["object","str","Text"],"display_name":"Chat Memory","documentation":"","custom_fields":{"sender":null,"sender_name":null,"session_id":null,"n_messages":null,"order":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":true},"id":"MemoryComponent-9ROme"},"selected":false,"width":384,"height":505,"positionAbsolute":{"x":261.78231532585994,"y":693.4279514516769},"dragging":false},{"id":"AzureOpenAIModel-3adzt","type":"genericNode","position":{"x":1845.4577690261672,"y":244.68176084584803},"data":{"type":"AzureOpenAIModel","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"input_types":["Text","Record","Prompt"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"api_key","display_name":"API Key","advanced":false,"dynamic":false,"info":"","load_from_db":true,"title_case":false,"input_types":["Text"],"value":""},"api_version":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"value":"2023-12-01-preview","fileTypes":[],"file_path":"","password":false,"options":["2023-03-15-preview","2023-05-15","2023-06-01-preview","2023-07-01-preview","2023-08-01-preview","2023-09-01-preview","2023-12-01-preview"],"name":"api_version","display_name":"API Version","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"azure_deployment":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"azure_deployment","display_name":"Deployment Name","advanced":false,"dynamic":false,"info":"","load_from_db":true,"title_case":false,"input_types":["Text"],"value":"AZURE_OPENAI_DEPLOYMENT_NAME"},"azure_endpoint":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"azure_endpoint","display_name":"Azure Endpoint","advanced":false,"dynamic":false,"info":"Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`","load_from_db":true,"title_case":false,"input_types":["Text"],"value":"AZURE_OPENAI_ENDPOINT"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_openai import AzureChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Text\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n\n    field_order = [\n        \"model\",\n        \"azure_endpoint\",\n        \"azure_deployment\",\n        \"api_version\",\n        \"api_key\",\n        \"temperature\",\n        \"max_tokens\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    AZURE_OPENAI_MODELS = [\n        \"gpt-35-turbo\",\n        \"gpt-35-turbo-16k\",\n        \"gpt-35-turbo-instruct\",\n        \"gpt-4\",\n        \"gpt-4-32k\",\n        \"gpt-4-vision\",\n    ]\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n        \"2023-09-01-preview\",\n        \"2023-12-01-preview\",\n    ]\n\n    def build_config(self):\n        return {\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": self.AZURE_OPENAI_MODELS[0],\n                \"options\": self.AZURE_OPENAI_MODELS,\n            },\n            \"azure_endpoint\": {\n                \"display_name\": \"Azure Endpoint\",\n                \"info\": \"Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`\",\n            },\n            \"azure_deployment\": {\n                \"display_name\": \"Deployment Name\",\n            },\n            \"api_version\": {\n                \"display_name\": \"API Version\",\n                \"options\": self.AZURE_OPENAI_API_VERSIONS,\n                \"value\": self.AZURE_OPENAI_API_VERSIONS[-1],\n                \"advanced\": True,\n            },\n            \"api_key\": {\"display_name\": \"API Key\", \"password\": True},\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"value\": 0.7,\n            },\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"advanced\": True,\n                \"info\": \"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            },\n            \"code\": {\"show\": False},\n            \"input_value\": {\"display_name\": \"Input\", \"input_types\": [\"Text\", \"Record\", \"Prompt\"]},\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        model: str,\n        azure_endpoint: str,\n        input_value: Text,\n        azure_deployment: str,\n        api_version: str,\n        api_key: str,\n        temperature: float,\n        system_message: Optional[str] = None,\n        max_tokens: Optional[int] = 1000,\n        stream: bool = False,\n    ) -> Text:\n        if api_key:\n            secret_api_key = SecretStr(api_key)\n        else:\n            secret_api_key = None\n        try:\n            output = AzureChatOpenAI(\n                model=model,\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=secret_api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to AzureOpenAI API.\") from e\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":1000,"fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","load_from_db":false,"title_case":false},"model":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"value":"gpt-4-32k","fileTypes":[],"file_path":"","password":false,"options":["gpt-35-turbo","gpt-35-turbo-16k","gpt-35-turbo-instruct","gpt-4","gpt-4-32k","gpt-4-vision"],"name":"model","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"system_message":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":"0.4","fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generate text using Azure OpenAI LLMs.","icon":"Azure","base_classes":["object","str","Text"],"display_name":"Azure OpenAI","documentation":"https://python.langchain.com/docs/integrations/llms/azure_openai","custom_fields":{"model":null,"azure_endpoint":null,"input_value":null,"azure_deployment":null,"api_version":null,"api_key":null,"temperature":null,"system_message":null,"max_tokens":null,"stream":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["model","azure_endpoint","azure_deployment","api_version","api_key","temperature","max_tokens","input_value","system_message","stream"],"beta":false},"id":"AzureOpenAIModel-3adzt"},"selected":false,"width":384,"height":762,"positionAbsolute":{"x":1845.4577690261672,"y":244.68176084584803},"dragging":false},{"id":"ChatOutput-eRYBk","type":"genericNode","position":{"x":2319,"y":606.1000061035156},"data":{"type":"ChatOutput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        return_message: Optional[bool] = False,\n    ) -> Union[Message, Text]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            files=files,\n            return_message=return_message,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"return_message":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_message","display_name":"Return Message","advanced":true,"dynamic":false,"info":"Return the message as a Message containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"AI","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message","object","str","Text"],"display_name":"Chat Output","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"files":null,"return_message":null},"output_types":["Message","Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatOutput-eRYBk"},"selected":false,"width":384,"height":297,"positionAbsolute":{"x":2319,"y":606.1000061035156},"dragging":false},{"id":"Chroma-RrDRD","type":"genericNode","position":{"x":1373.5708707610731,"y":1664.1067329878745},"data":{"type":"Chroma","node":{"template":{"embedding":{"type":"Embeddings","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"embedding","display_name":"Embedding","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"inputs":{"type":"Record","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"inputs","display_name":"Input","advanced":false,"input_types":["Document","Record"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"allow_duplicates":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"allow_duplicates","display_name":"Allow Duplicates","advanced":true,"dynamic":false,"info":"If false, will not add documents that are already in the Vector Store.","load_from_db":false,"title_case":false},"chroma_server_cors_allow_origins":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":[],"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_cors_allow_origins","display_name":"Server CORS Allow Origins","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"chroma_server_grpc_port":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_grpc_port","display_name":"Server gRPC Port","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"chroma_server_host":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_host","display_name":"Server Host","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"chroma_server_http_port":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_http_port","display_name":"Server HTTP Port","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"chroma_server_ssl_enabled":{"type":"bool","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_ssl_enabled","display_name":"Server SSL Enabled","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from copy import deepcopy\nfrom typing import List, Optional, Union\n\nimport chromadb\nfrom chromadb.config import Settings\nfrom langchain_chroma import Chroma\nfrom langchain_core.embeddings import Embeddings\nfrom langchain_core.retrievers import BaseRetriever\nfrom langchain_core.vectorstores import VectorStore\n\nfrom langflow.base.vectorstores.utils import chroma_collection_to_records\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\n\n\nclass ChromaComponent(CustomComponent):\n    \"\"\"\n    A custom component for implementing a Vector Store using Chroma.\n    \"\"\"\n\n    display_name: str = \"Chroma\"\n    description: str = \"Implementation of Vector Store using Chroma\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/chroma\"\n    icon = \"Chroma\"\n\n    def build_config(self):\n        \"\"\"\n        Builds the configuration for the component.\n\n        Returns:\n        - dict: A dictionary containing the configuration options for the component.\n        \"\"\"\n        return {\n            \"collection_name\": {\"display_name\": \"Collection Name\", \"value\": \"langflow\"},\n            \"index_directory\": {\"display_name\": \"Persist Directory\"},\n            \"code\": {\"advanced\": True, \"display_name\": \"Code\"},\n            \"inputs\": {\"display_name\": \"Input\", \"input_types\": [\"Document\", \"Record\"]},\n            \"embedding\": {\"display_name\": \"Embedding\"},\n            \"chroma_server_cors_allow_origins\": {\n                \"display_name\": \"Server CORS Allow Origins\",\n                \"advanced\": True,\n            },\n            \"chroma_server_host\": {\"display_name\": \"Server Host\", \"advanced\": True},\n            \"chroma_server_http_port\": {\"display_name\": \"Server HTTP Port\", \"advanced\": True},\n            \"chroma_server_grpc_port\": {\n                \"display_name\": \"Server gRPC Port\",\n                \"advanced\": True,\n            },\n            \"chroma_server_ssl_enabled\": {\n                \"display_name\": \"Server SSL Enabled\",\n                \"advanced\": True,\n            },\n            \"allow_duplicates\": {\n                \"display_name\": \"Allow Duplicates\",\n                \"advanced\": True,\n                \"info\": \"If false, will not add documents that are already in the Vector Store.\",\n            },\n        }\n\n    def build(\n        self,\n        collection_name: str,\n        embedding: Embeddings,\n        chroma_server_ssl_enabled: bool,\n        index_directory: Optional[str] = None,\n        inputs: Optional[List[Record]] = None,\n        chroma_server_cors_allow_origins: List[str] = [],\n        chroma_server_host: Optional[str] = None,\n        chroma_server_http_port: Optional[int] = None,\n        chroma_server_grpc_port: Optional[int] = None,\n        allow_duplicates: bool = False,\n    ) -> Union[VectorStore, BaseRetriever]:\n        \"\"\"\n        Builds the Vector Store or BaseRetriever object.\n\n        Args:\n        - collection_name (str): The name of the collection.\n        - embedding (Embeddings): The embeddings to use for the Vector Store.\n        - chroma_server_ssl_enabled (bool): Whether to enable SSL for the Chroma server.\n        - index_directory (Optional[str]): The directory to persist the Vector Store to.\n        - inputs (Optional[List[Record]]): The input records to use for the Vector Store.\n        - chroma_server_cors_allow_origins (List[str]): The CORS allow origins for the Chroma server.\n        - chroma_server_host (Optional[str]): The host for the Chroma server.\n        - chroma_server_http_port (Optional[int]): The HTTP port for the Chroma server.\n        - chroma_server_grpc_port (Optional[int]): The gRPC port for the Chroma server.\n        - allow_duplicates (bool): Whether to allow duplicates in the Vector Store.\n\n        Returns:\n        - Union[VectorStore, BaseRetriever]: The Vector Store or BaseRetriever object.\n        \"\"\"\n\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if chroma_server_host is not None:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=chroma_server_cors_allow_origins or [],\n                chroma_server_host=chroma_server_host,\n                chroma_server_http_port=chroma_server_http_port or None,\n                chroma_server_grpc_port=chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=chroma_server_ssl_enabled,\n            )\n            client = chromadb.HttpClient(settings=chroma_settings)\n\n        # Check index_directory and expand it if it is a relative path\n        if index_directory is not None:\n            index_directory = self.resolve_path(index_directory)\n\n        chroma = Chroma(\n            persist_directory=index_directory,\n            client=client,\n            embedding_function=embedding,\n            collection_name=collection_name,\n        )\n        if allow_duplicates:\n            stored_records = []\n        else:\n            stored_records = chroma_collection_to_records(chroma.get())\n            _stored_documents_without_id = []\n            for record in deepcopy(stored_records):\n                del record.id\n                _stored_documents_without_id.append(record)\n        documents = []\n        for _input in inputs or []:\n            if isinstance(_input, Record):\n                if _input not in _stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Inputs must be a Record objects.\")\n\n        if documents and embedding is not None:\n            chroma.add_documents(documents)\n\n        self.status = stored_records\n        return chroma\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":"langflow-restauranta-q-and-a","fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"index_directory":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"index_directory","display_name":"Persist Directory","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Implementation of Vector Store using Chroma","icon":"Chroma","base_classes":["BaseRetriever","Generic","object","Runnable","RunnableSerializable","Serializable","VectorStore"],"display_name":"Chroma","documentation":"https://python.langchain.com/docs/integrations/vectorstores/chroma","custom_fields":{"collection_name":null,"embedding":null,"chroma_server_ssl_enabled":null,"index_directory":null,"inputs":null,"chroma_server_cors_allow_origins":null,"chroma_server_host":null,"chroma_server_http_port":null,"chroma_server_grpc_port":null,"allow_duplicates":null},"output_types":["VectorStore","BaseRetriever"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"Chroma-RrDRD"},"selected":false,"width":384,"height":487,"positionAbsolute":{"x":1373.5708707610731,"y":1664.1067329878745},"dragging":false},{"id":"AzureOpenAIEmbeddings-2Lv5d","type":"genericNode","position":{"x":735.7198279116062,"y":1193.8843157518522},"data":{"type":"AzureOpenAIEmbeddings","node":{"template":{"api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"api_key","display_name":"API Key","advanced":false,"dynamic":false,"info":"","load_from_db":true,"title_case":false,"input_types":["Text"],"value":""},"api_version":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"value":"2023-08-01-preview","fileTypes":[],"file_path":"","password":false,"options":["2022-12-01","2023-03-15-preview","2023-05-15","2023-06-01-preview","2023-07-01-preview","2023-08-01-preview"],"name":"api_version","display_name":"API Version","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"azure_deployment":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"azure_deployment","display_name":"Deployment Name","advanced":false,"dynamic":false,"info":"","load_from_db":true,"title_case":false,"input_types":["Text"],"value":"AZURE_OPENAI_DEPLOYMENTNAME_EMBEDDED"},"azure_endpoint":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"azure_endpoint","display_name":"Azure Endpoint","advanced":false,"dynamic":false,"info":"Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`","load_from_db":true,"title_case":false,"input_types":["Text"],"value":"AZURE_OPENAI_ENDPOINT"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_core.embeddings import Embeddings\nfrom langchain_openai import AzureOpenAIEmbeddings\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.custom import CustomComponent\n\n\nclass AzureOpenAIEmbeddingsComponent(CustomComponent):\n    display_name: str = \"Azure OpenAI Embeddings\"\n    description: str = \"Generate embeddings using Azure OpenAI models.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/text_embedding/azureopenai\"\n    beta = False\n    icon = \"Azure\"\n\n    API_VERSION_OPTIONS = [\n        \"2022-12-01\",\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n    ]\n\n    def build_config(self):\n        return {\n            \"azure_endpoint\": {\n                \"display_name\": \"Azure Endpoint\",\n                \"required\": True,\n                \"info\": \"Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`\",\n            },\n            \"azure_deployment\": {\n                \"display_name\": \"Deployment Name\",\n                \"required\": True,\n            },\n            \"api_version\": {\n                \"display_name\": \"API Version\",\n                \"options\": self.API_VERSION_OPTIONS,\n                \"value\": self.API_VERSION_OPTIONS[-1],\n                \"advanced\": True,\n            },\n            \"api_key\": {\n                \"display_name\": \"API Key\",\n                \"required\": True,\n                \"password\": True,\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        azure_endpoint: str,\n        azure_deployment: str,\n        api_version: str,\n        api_key: str,\n    ) -> Embeddings:\n        if api_key:\n            azure_api_key = SecretStr(api_key)\n        else:\n            azure_api_key = None\n        try:\n            embeddings = AzureOpenAIEmbeddings(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=azure_api_key,\n            )\n\n        except Exception as e:\n            raise ValueError(\"Could not connect to AzureOpenAIEmbeddings API.\") from e\n\n        return embeddings\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generate embeddings using Azure OpenAI models.","icon":"Azure","base_classes":["Embeddings"],"display_name":"Azure OpenAI Embeddings","documentation":"https://python.langchain.com/docs/integrations/text_embedding/azureopenai","custom_fields":{"azure_endpoint":null,"azure_deployment":null,"api_version":null,"api_key":null},"output_types":["Embeddings"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"AzureOpenAIEmbeddings-2Lv5d"},"selected":false,"width":384,"height":516,"dragging":false,"positionAbsolute":{"x":735.7198279116062,"y":1193.8843157518522}},{"id":"File-j9lfT","type":"genericNode","position":{"x":-467.06523398607396,"y":1745.8635454782866},"data":{"type":"File","node":{"template":{"path":{"type":"file","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx"],"file_path":"60bd1dcb-be4f-486a-ab72-9227d7991edf/customers-100.csv","password":false,"name":"path","display_name":"Path","advanced":false,"dynamic":false,"info":"Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from pathlib import Path\nfrom typing import Any, Dict\n\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_record\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\n\n\nclass FileComponent(CustomComponent):\n    display_name = \"File\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n\n    def build_config(self) -> Dict[str, Any]:\n        return {\n            \"path\": {\n                \"display_name\": \"Path\",\n                \"field_type\": \"file\",\n                \"file_types\": TEXT_FILE_TYPES,\n                \"info\": f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n            },\n            \"silent_errors\": {\n                \"display_name\": \"Silent Errors\",\n                \"advanced\": True,\n                \"info\": \"If true, errors will not raise an exception.\",\n            },\n        }\n\n    def load_file(self, path: str, silent_errors: bool = False) -> Record:\n        resolved_path = self.resolve_path(path)\n        path_obj = Path(resolved_path)\n        extension = path_obj.suffix[1:].lower()\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n        record = parse_text_file_to_record(resolved_path, silent_errors)\n        self.status = record if record else \"No data\"\n        return record or Record()\n\n    def build(\n        self,\n        path: str,\n        silent_errors: bool = False,\n    ) -> Record:\n        record = self.load_file(path, silent_errors)\n        self.status = record\n        return record\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"silent_errors":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"silent_errors","display_name":"Silent Errors","advanced":true,"dynamic":false,"info":"If true, errors will not raise an exception.","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"A generic file loader.","icon":"file-text","base_classes":["Record"],"display_name":"File","documentation":"","custom_fields":{"path":null,"silent_errors":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":false},"id":"File-j9lfT","description":"A generic file loader.","display_name":"File"},"selected":false,"width":384,"height":289,"positionAbsolute":{"x":-467.06523398607396,"y":1745.8635454782866},"dragging":false},{"id":"ChromaSearch-80dAc","type":"genericNode","position":{"x":1290.7855488715027,"y":418.446657863891},"data":{"type":"ChromaSearch","node":{"template":{"embedding":{"type":"Embeddings","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"embedding","display_name":"Embedding","advanced":false,"dynamic":false,"info":"Embedding model to vectorize inputs (make sure to use same as index)","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"chroma_server_cors_allow_origins":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":[],"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_cors_allow_origins","display_name":"Server CORS Allow Origins","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"chroma_server_grpc_port":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_grpc_port","display_name":"Server gRPC Port","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"chroma_server_host":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_host","display_name":"Server Host","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"chroma_server_http_port":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_http_port","display_name":"Server HTTP Port","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"chroma_server_ssl_enabled":{"type":"bool","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_ssl_enabled","display_name":"Server SSL Enabled","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional\n\nimport chromadb\nfrom chromadb.config import Settings\nfrom langchain_chroma import Chroma\n\nfrom langflow.components.vectorstores.base.model import LCVectorStoreComponent\nfrom langflow.field_typing import Embeddings, Text\nfrom langflow.schema import Record\n\n\nclass ChromaSearchComponent(LCVectorStoreComponent):\n    display_name: str = \"Chroma Search\"\n    description: str = \"Search a Chroma collection for similar documents.\"\n    icon = \"Chroma\"\n\n    def build_config(self):\n        \"\"\"\n        Builds the configuration for the component.\n\n        Returns:\n        - dict: A dictionary containing the configuration options for the component.\n        \"\"\"\n        return {\n            \"input_value\": {\"display_name\": \"Input\"},\n            \"search_type\": {\n                \"display_name\": \"Search Type\",\n                \"options\": [\"Similarity\", \"MMR\"],\n            },\n            \"collection_name\": {\"display_name\": \"Collection Name\", \"value\": \"langflow\"},\n            # \"persist\": {\"display_name\": \"Persist\"},\n            \"index_directory\": {\"display_name\": \"Index Directory\"},\n            \"code\": {\"show\": False, \"display_name\": \"Code\"},\n            \"embedding\": {\n                \"display_name\": \"Embedding\",\n                \"info\": \"Embedding model to vectorize inputs (make sure to use same as index)\",\n            },\n            \"chroma_server_cors_allow_origins\": {\n                \"display_name\": \"Server CORS Allow Origins\",\n                \"advanced\": True,\n            },\n            \"chroma_server_host\": {\"display_name\": \"Server Host\", \"advanced\": True},\n            \"chroma_server_http_port\": {\"display_name\": \"Server HTTP Port\", \"advanced\": True},\n            \"chroma_server_grpc_port\": {\n                \"display_name\": \"Server gRPC Port\",\n                \"advanced\": True,\n            },\n            \"chroma_server_ssl_enabled\": {\n                \"display_name\": \"Server SSL Enabled\",\n                \"advanced\": True,\n            },\n            \"number_of_results\": {\n                \"display_name\": \"Number of Results\",\n                \"info\": \"Number of results to return.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        search_type: str,\n        collection_name: str,\n        embedding: Embeddings,\n        chroma_server_ssl_enabled: bool,\n        number_of_results: int = 4,\n        index_directory: Optional[str] = None,\n        chroma_server_cors_allow_origins: List[str] = [],\n        chroma_server_host: Optional[str] = None,\n        chroma_server_http_port: Optional[int] = None,\n        chroma_server_grpc_port: Optional[int] = None,\n    ) -> List[Record]:\n        \"\"\"\n        Builds the Vector Store or BaseRetriever object.\n\n        Args:\n        - input_value (Text): The input value.\n        - search_type (str): The type of search.\n        - collection_name (str): The name of the collection.\n        - embedding (Embeddings): The embeddings to use for the Vector Store.\n        - chroma_server_ssl_enabled (bool): Whether to enable SSL for the Chroma server.\n        - number_of_results (int, optional): The number of results to retrieve. Defaults to 4.\n        - index_directory (str, optional): The directory to persist the Vector Store to. Defaults to None.\n        - chroma_server_cors_allow_origins (List[str], optional): The CORS allow origins for the Chroma server. Defaults to [].\n        - chroma_server_host (str, optional): The host for the Chroma server. Defaults to None.\n        - chroma_server_http_port (int, optional): The HTTP port for the Chroma server. Defaults to None.\n        - chroma_server_grpc_port (int, optional): The gRPC port for the Chroma server. Defaults to None.\n\n        Returns:\n        - List[Record]: The list of records.\n        \"\"\"\n\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if chroma_server_host is not None:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=chroma_server_cors_allow_origins or [],\n                chroma_server_host=chroma_server_host,\n                chroma_server_http_port=chroma_server_http_port or None,\n                chroma_server_grpc_port=chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=chroma_server_ssl_enabled,\n            )\n            client = chromadb.HttpClient(settings=chroma_settings)\n        if index_directory:\n            index_directory = self.resolve_path(index_directory)\n        vector_store = Chroma(\n            embedding_function=embedding,\n            collection_name=collection_name,\n            persist_directory=index_directory,\n            client=client,\n        )\n\n        return self.search_with_vector_store(input_value, search_type, vector_store, k=number_of_results)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":"langflow-restauranta-q-and-a","fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"index_directory":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"index_directory","display_name":"Index Directory","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"number_of_results":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":4,"fileTypes":[],"file_path":"","password":false,"name":"number_of_results","display_name":"Number of Results","advanced":true,"dynamic":false,"info":"Number of results to return.","load_from_db":false,"title_case":false},"search_type":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"options":["Similarity","MMR"],"name":"search_type","display_name":"Search Type","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"Similarity"},"_type":"CustomComponent"},"description":"Search a Chroma collection for similar documents.","icon":"Chroma","base_classes":["Record"],"display_name":"Chroma Search","documentation":"","custom_fields":{"input_value":null,"search_type":null,"collection_name":null,"embedding":null,"chroma_server_ssl_enabled":null,"number_of_results":null,"index_directory":null,"chroma_server_cors_allow_origins":null,"chroma_server_host":null,"chroma_server_http_port":null,"chroma_server_grpc_port":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChromaSearch-80dAc"},"selected":false,"width":384,"height":655,"positionAbsolute":{"x":1290.7855488715027,"y":418.446657863891},"dragging":false},{"id":"CharacterTextSplitter-Mi8H6","type":"genericNode","position":{"x":591.8916510630003,"y":1927.9234008786086},"data":{"type":"CharacterTextSplitter","node":{"template":{"inputs":{"type":"Record","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"inputs","display_name":"Input","advanced":false,"input_types":["Document","Record"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"chunk_overlap":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":200,"fileTypes":[],"file_path":"","password":false,"name":"chunk_overlap","display_name":"Chunk Overlap","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"chunk_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":1000,"fileTypes":[],"file_path":"","password":false,"name":"chunk_size","display_name":"Chunk Size","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List\n\nfrom langchain_text_splitters import CharacterTextSplitter\n\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\nfrom langflow.utils.util import unescape_string\n\n\nclass CharacterTextSplitterComponent(CustomComponent):\n    display_name = \"CharacterTextSplitter\"\n    description = \"Splitting text that looks at characters.\"\n\n    def build_config(self):\n        return {\n            \"inputs\": {\"display_name\": \"Input\", \"input_types\": [\"Document\", \"Record\"]},\n            \"chunk_overlap\": {\"display_name\": \"Chunk Overlap\", \"default\": 200},\n            \"chunk_size\": {\"display_name\": \"Chunk Size\", \"default\": 1000},\n            \"separator\": {\"display_name\": \"Separator\", \"default\": \"\\n\"},\n        }\n\n    def build(\n        self,\n        inputs: List[Record],\n        chunk_overlap: int = 200,\n        chunk_size: int = 1000,\n        separator: str = \"\\n\",\n    ) -> List[Record]:\n        # separator may come escaped from the frontend\n        separator = unescape_string(separator)\n        documents = []\n        for _input in inputs:\n            if isinstance(_input, Record):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        docs = CharacterTextSplitter(\n            chunk_overlap=chunk_overlap,\n            chunk_size=chunk_size,\n            separator=separator,\n        ).split_documents(documents)\n        records = self.to_records(docs)\n        self.status = records\n        return records\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"separator":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":",","fileTypes":[],"file_path":"","password":false,"name":"separator","display_name":"Separator","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Splitting text that looks at characters.","base_classes":["Record"],"display_name":"CharacterTextSplitter","documentation":"","custom_fields":{"inputs":null,"chunk_overlap":null,"chunk_size":null,"separator":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"CharacterTextSplitter-Mi8H6"},"selected":false,"width":384,"height":517,"positionAbsolute":{"x":591.8916510630003,"y":1927.9234008786086},"dragging":false}],"edges":[{"source":"TextInput-lzJYa","sourceHandle":"{baseClasses:[object,str,Text],dataType:TextInput,id:TextInput-lzJYa}","target":"ChatInput-nCUEa","targetHandle":"{fieldName:sender_name,id:ChatInput-nCUEa,inputTypes:[Text],type:str}","data":{"targetHandle":{"fieldName":"sender_name","id":"ChatInput-nCUEa","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"TextInput","id":"TextInput-lzJYa"}},"id":"reactflow__edge-TextInput-lzJYa{baseClasses:[object,str,Text],dataType:TextInput,id:TextInput-lzJYa}-ChatInput-nCUEa{fieldName:sender_name,id:ChatInput-nCUEa,inputTypes:[Text],type:str}","className":""},{"source":"ChatInput-nCUEa","sourceHandle":"{baseClasses:[Message,object,str,Text],dataType:ChatInput,id:ChatInput-nCUEa}","target":"Prompt-Ts5jb","targetHandle":"{fieldName:question,id:Prompt-Ts5jb,inputTypes:[Document,Message,Record,Text],type:str}","data":{"targetHandle":{"fieldName":"question","id":"Prompt-Ts5jb","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Message","object","str","Text"],"dataType":"ChatInput","id":"ChatInput-nCUEa"}},"id":"reactflow__edge-ChatInput-nCUEa{baseClasses:[Message,object,str,Text],dataType:ChatInput,id:ChatInput-nCUEa}-Prompt-Ts5jb{fieldName:question,id:Prompt-Ts5jb,inputTypes:[Document,Message,Record,Text],type:str}","className":""},{"source":"TextInput-lzJYa","sourceHandle":"{baseClasses:[object,str,Text],dataType:TextInput,id:TextInput-lzJYa}","target":"MemoryComponent-9ROme","targetHandle":"{fieldName:session_id,id:MemoryComponent-9ROme,inputTypes:[Text],type:str}","data":{"targetHandle":{"fieldName":"session_id","id":"MemoryComponent-9ROme","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"TextInput","id":"TextInput-lzJYa"}},"id":"reactflow__edge-TextInput-lzJYa{baseClasses:[object,str,Text],dataType:TextInput,id:TextInput-lzJYa}-MemoryComponent-9ROme{fieldName:session_id,id:MemoryComponent-9ROme,inputTypes:[Text],type:str}","className":""},{"source":"MemoryComponent-9ROme","sourceHandle":"{baseClasses:[object,str,Text],dataType:MemoryComponent,id:MemoryComponent-9ROme}","target":"Prompt-Ts5jb","targetHandle":"{fieldName:history,id:Prompt-Ts5jb,inputTypes:[Document,Message,Record,Text],type:str}","data":{"targetHandle":{"fieldName":"history","id":"Prompt-Ts5jb","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"MemoryComponent","id":"MemoryComponent-9ROme"}},"id":"reactflow__edge-MemoryComponent-9ROme{baseClasses:[object,str,Text],dataType:MemoryComponent,id:MemoryComponent-9ROme}-Prompt-Ts5jb{fieldName:history,id:Prompt-Ts5jb,inputTypes:[Document,Message,Record,Text],type:str}","className":""},{"source":"Prompt-Ts5jb","sourceHandle":"{baseClasses:[Prompt,Record],dataType:Prompt,id:Prompt-Ts5jb}","target":"AzureOpenAIModel-3adzt","targetHandle":"{fieldName:input_value,id:AzureOpenAIModel-3adzt,inputTypes:[Text,Record,Prompt],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"AzureOpenAIModel-3adzt","inputTypes":["Text","Record","Prompt"],"type":"str"},"sourceHandle":{"baseClasses":["Prompt","Record"],"dataType":"Prompt","id":"Prompt-Ts5jb"}},"id":"reactflow__edge-Prompt-Ts5jb{baseClasses:[Prompt,Record],dataType:Prompt,id:Prompt-Ts5jb}-AzureOpenAIModel-3adzt{fieldName:input_value,id:AzureOpenAIModel-3adzt,inputTypes:[Text,Record,Prompt],type:str}","className":""},{"source":"AzureOpenAIModel-3adzt","sourceHandle":"{baseClasses:[object,str,Text],dataType:AzureOpenAIModel,id:AzureOpenAIModel-3adzt}","target":"ChatOutput-eRYBk","targetHandle":"{fieldName:input_value,id:ChatOutput-eRYBk,inputTypes:[Text],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-eRYBk","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"AzureOpenAIModel","id":"AzureOpenAIModel-3adzt"}},"id":"reactflow__edge-AzureOpenAIModel-3adzt{baseClasses:[object,str,Text],dataType:AzureOpenAIModel,id:AzureOpenAIModel-3adzt}-ChatOutput-eRYBk{fieldName:input_value,id:ChatOutput-eRYBk,inputTypes:[Text],type:str}","className":""},{"source":"AzureOpenAIEmbeddings-2Lv5d","sourceHandle":"{baseClasses:[Embeddings],dataType:AzureOpenAIEmbeddings,id:AzureOpenAIEmbeddings-2Lv5d}","target":"Chroma-RrDRD","targetHandle":"{fieldName:embedding,id:Chroma-RrDRD,inputTypes:null,type:Embeddings}","data":{"targetHandle":{"fieldName":"embedding","id":"Chroma-RrDRD","inputTypes":null,"type":"Embeddings"},"sourceHandle":{"baseClasses":["Embeddings"],"dataType":"AzureOpenAIEmbeddings","id":"AzureOpenAIEmbeddings-2Lv5d"}},"id":"reactflow__edge-AzureOpenAIEmbeddings-2Lv5d{baseClasses:[Embeddings],dataType:AzureOpenAIEmbeddings,id:AzureOpenAIEmbeddings-2Lv5d}-Chroma-RrDRD{fieldName:embedding,id:Chroma-RrDRD,inputTypes:null,type:Embeddings}","className":""},{"source":"AzureOpenAIEmbeddings-2Lv5d","sourceHandle":"{baseClasses:[Embeddings],dataType:AzureOpenAIEmbeddings,id:AzureOpenAIEmbeddings-2Lv5d}","target":"ChromaSearch-80dAc","targetHandle":"{fieldName:embedding,id:ChromaSearch-80dAc,inputTypes:null,type:Embeddings}","data":{"targetHandle":{"fieldName":"embedding","id":"ChromaSearch-80dAc","inputTypes":null,"type":"Embeddings"},"sourceHandle":{"baseClasses":["Embeddings"],"dataType":"AzureOpenAIEmbeddings","id":"AzureOpenAIEmbeddings-2Lv5d"}},"id":"reactflow__edge-AzureOpenAIEmbeddings-2Lv5d{baseClasses:[Embeddings],dataType:AzureOpenAIEmbeddings,id:AzureOpenAIEmbeddings-2Lv5d}-ChromaSearch-80dAc{fieldName:embedding,id:ChromaSearch-80dAc,inputTypes:null,type:Embeddings}","className":""},{"source":"ChatInput-nCUEa","sourceHandle":"{baseClasses:[Message,object,str,Text],dataType:ChatInput,id:ChatInput-nCUEa}","target":"ChromaSearch-80dAc","targetHandle":"{fieldName:input_value,id:ChromaSearch-80dAc,inputTypes:[Text],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"ChromaSearch-80dAc","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["Message","object","str","Text"],"dataType":"ChatInput","id":"ChatInput-nCUEa"}},"id":"reactflow__edge-ChatInput-nCUEa{baseClasses:[Message,object,str,Text],dataType:ChatInput,id:ChatInput-nCUEa}-ChromaSearch-80dAc{fieldName:input_value,id:ChromaSearch-80dAc,inputTypes:[Text],type:str}","className":""},{"source":"ChromaSearch-80dAc","sourceHandle":"{baseClasses:[Record],dataType:ChromaSearch,id:ChromaSearch-80dAc}","target":"Prompt-Ts5jb","targetHandle":"{fieldName:context,id:Prompt-Ts5jb,inputTypes:[Document,Message,Record,Text],type:str}","data":{"targetHandle":{"fieldName":"context","id":"Prompt-Ts5jb","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Record"],"dataType":"ChromaSearch","id":"ChromaSearch-80dAc"}},"id":"reactflow__edge-ChromaSearch-80dAc{baseClasses:[Record],dataType:ChromaSearch,id:ChromaSearch-80dAc}-Prompt-Ts5jb{fieldName:context,id:Prompt-Ts5jb,inputTypes:[Document,Message,Record,Text],type:str}","className":""},{"source":"CharacterTextSplitter-Mi8H6","sourceHandle":"{baseClasses:[Record],dataType:CharacterTextSplitter,id:CharacterTextSplitter-Mi8H6}","target":"Chroma-RrDRD","targetHandle":"{fieldName:inputs,id:Chroma-RrDRD,inputTypes:[Document,Record],type:Record}","data":{"targetHandle":{"fieldName":"inputs","id":"Chroma-RrDRD","inputTypes":["Document","Record"],"type":"Record"},"sourceHandle":{"baseClasses":["Record"],"dataType":"CharacterTextSplitter","id":"CharacterTextSplitter-Mi8H6"}},"id":"reactflow__edge-CharacterTextSplitter-Mi8H6{baseClasses:[Record],dataType:CharacterTextSplitter,id:CharacterTextSplitter-Mi8H6}-Chroma-RrDRD{fieldName:inputs,id:Chroma-RrDRD,inputTypes:[Document,Record],type:Record}"},{"source":"File-j9lfT","sourceHandle":"{baseClasses:[Record],dataType:File,id:File-j9lfT}","target":"CharacterTextSplitter-Mi8H6","targetHandle":"{fieldName:inputs,id:CharacterTextSplitter-Mi8H6,inputTypes:[Document,Record],type:Record}","data":{"targetHandle":{"fieldName":"inputs","id":"CharacterTextSplitter-Mi8H6","inputTypes":["Document","Record"],"type":"Record"},"sourceHandle":{"baseClasses":["Record"],"dataType":"File","id":"File-j9lfT"}},"id":"reactflow__edge-File-j9lfT{baseClasses:[Record],dataType:File,id:File-j9lfT}-CharacterTextSplitter-Mi8H6{fieldName:inputs,id:CharacterTextSplitter-Mi8H6,inputTypes:[Document,Record],type:Record}"}],"viewport":{"x":600.6007148223273,"y":182.05281822131758,"zoom":0.31731772150495097}},"description":"Engineered for Excellence, Built for Business.","name":"Experiment: RAG Based LLM App","last_tested_version":"1.0.0a52","is_component":false}