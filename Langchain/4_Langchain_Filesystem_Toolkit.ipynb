{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using deployment name: gpt-4o\n",
      "Prompt template created.\n",
      "Chat history initialized.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Button' object has no attribute 'upload'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 207\u001b[0m\n\u001b[1;32m    205\u001b[0m save_button\u001b[38;5;241m.\u001b[39mclick(fn\u001b[38;5;241m=\u001b[39mhandle_save_click, inputs\u001b[38;5;241m=\u001b[39m[], outputs\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    206\u001b[0m save_as_button\u001b[38;5;241m.\u001b[39mclick(fn\u001b[38;5;241m=\u001b[39mtrigger_save_as_dialog, inputs\u001b[38;5;241m=\u001b[39m[], outputs\u001b[38;5;241m=\u001b[39m[save_as_button])\n\u001b[0;32m--> 207\u001b[0m \u001b[43msave_as_button\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload\u001b[49m(fn\u001b[38;5;241m=\u001b[39mhandle_save_as_click, inputs\u001b[38;5;241m=\u001b[39msave_as_button, outputs\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    208\u001b[0m open_file\u001b[38;5;241m.\u001b[39mupload(fn\u001b[38;5;241m=\u001b[39mhandle_open_file, inputs\u001b[38;5;241m=\u001b[39mopen_file, outputs\u001b[38;5;241m=\u001b[39m[chatbot])\n\u001b[1;32m    209\u001b[0m delete_all_button\u001b[38;5;241m.\u001b[39mclick(fn\u001b[38;5;241m=\u001b[39mhandle_delete_all_click, inputs\u001b[38;5;241m=\u001b[39m[], outputs\u001b[38;5;241m=\u001b[39m[])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Button' object has no attribute 'upload'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import asyncio\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "import gradio as gr\n",
    "\n",
    "# Check environment variable\n",
    "deployment_name = os.getenv(\"OPENAI_API_DEPLOYMENT_NAME\")\n",
    "if not deployment_name:\n",
    "    raise ValueError(\"OPENAI_API_DEPLOYMENT_NAME environment variable is not set.\")\n",
    "print(f\"Using deployment name: {deployment_name}\")\n",
    "\n",
    "# Initialize the model\n",
    "model = AzureChatOpenAI(deployment_name=deployment_name)\n",
    "\n",
    "# Function to read file contents\n",
    "def get_file_content(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filepath} not found.\")\n",
    "        return \"\"\n",
    "\n",
    "# Manage session history\n",
    "store = {}\n",
    "def get_session_history(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Function to get system prompt\n",
    "def get_system_prompt():\n",
    "    return get_file_content('./SystemPrompt-VSC-BusinesCentral-TestRunner.txt')\n",
    "\n",
    "file_paths = {\n",
    "    'al_endpoint': '../BusinessCentral-AL-Test-Runner-App/src/codeunit/WebApi.Codeunit.al',\n",
    "    'package_json': '../VSC-BusinessCentral-Test-Runner/package.json',\n",
    "    'apiclient_ts': '../VSC-BusinessCentral-Test-Runner/src/apiClient.ts',\n",
    "    'project_ts': '../VSC-BusinessCentral-Test-Runner/src/project.ts',\n",
    "    'testrunner_ts': '../VSC-BusinessCentral-Test-Runner/src/testRunner.ts',\n",
    "    'testviewproviders_ts': '../VSC-BusinessCentral-Test-Runner/src/testViewProviders.ts',\n",
    "    'extension_ts': '../VSC-BusinessCentral-Test-Runner/src/extension.ts',\n",
    "}\n",
    "\n",
    "file_contents = {key: get_file_content(path) for key, path in file_paths.items()}\n",
    "systemprompt = get_system_prompt()\n",
    "\n",
    "# Escape the curly braces\n",
    "def escape_curly_braces(s):\n",
    "    return s.replace('{', '{{').replace('}', '}}')\n",
    "\n",
    "system_message = SystemMessage(content=systemprompt)\n",
    "file_content_messages = [\n",
    "    SystemMessage(content=f\"#### This is the content of {key}: {escape_curly_braces(file_contents[key])}\\n---\")\n",
    "    for key in file_contents\n",
    "]\n",
    "user_message_template = HumanMessage(content=\"{input}\")\n",
    "messages = [system_message, *file_content_messages, user_message_template]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "print(\"Prompt template created.\")\n",
    "\n",
    "konnos_chat_history = get_session_history(\"default\")\n",
    "current_file_path = None\n",
    "print(\"Chat history initialized.\")\n",
    "\n",
    "def save_chat_history_as(file_path):\n",
    "    global current_file_path\n",
    "    try:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(konnos_chat_history.messages, f)\n",
    "        print(f\"Chat history saved as: {file_path}\")\n",
    "        current_file_path = file_path\n",
    "        return file_path\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save chat history: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_chat_history():\n",
    "    global current_file_path\n",
    "    if current_file_path is None:\n",
    "        return None\n",
    "    try:\n",
    "        with open(current_file_path, 'wb') as f:\n",
    "            pickle.dump(konnos_chat_history.messages, f)\n",
    "        print(f\"Chat history saved to: {current_file_path}\")\n",
    "        return current_file_path\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save chat history: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_chat_history(file_path):\n",
    "    global konnos_chat_history, current_file_path\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            konnos_chat_history.messages = pickle.load(f)\n",
    "        current_file_path = file_path\n",
    "        chat_entries = [(msg.content if isinstance(msg, HumanMessage) else \"\", msg.content if isinstance(msg, AIMessage) else \"\") for msg in konnos_chat_history.messages]\n",
    "        print(f\"Chat history loaded from: {file_path}\")\n",
    "        return chat_entries\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load chat history: {e}\")\n",
    "        return []\n",
    "\n",
    "async def converse(user_input):\n",
    "    print(f\"User input received: {user_input}\")\n",
    "    chat_history_list = konnos_chat_history.messages\n",
    "\n",
    "    formatted_prompt = prompt_template.format(\n",
    "        chat_history=chat_history_list,\n",
    "        input=user_input,\n",
    "        **file_contents\n",
    "    )\n",
    "\n",
    "    konnos_chat_history.add_message(HumanMessage(content=user_input))\n",
    "    print(\"Human message added to history.\")\n",
    "    \n",
    "    response = await asyncio.to_thread(model.invoke, formatted_prompt)\n",
    "    konnos_chat_history.add_message(AIMessage(content=response.content))\n",
    "    print(\"AI message added to history.\")\n",
    "    return response.content\n",
    "\n",
    "async def interactive_conversation_stream(user_input):\n",
    "    chat_history_list = konnos_chat_history.messages\n",
    "\n",
    "    formatted_prompt = prompt_template.format(\n",
    "        chat_history=chat_history_list,\n",
    "        input=user_input,\n",
    "        **file_contents\n",
    "    )\n",
    "\n",
    "    konnos_chat_history.add_message(HumanMessage(content=user_input))\n",
    "    print(\"Human message added to history.\")\n",
    "\n",
    "    response = await asyncio.to_thread(model.invoke, formatted_prompt)\n",
    "\n",
    "    konnos_chat_history.add_message(AIMessage(content=response.content))\n",
    "    print(\"AI message added to history.\")\n",
    "    \n",
    "    for char in response.content:\n",
    "        yield char\n",
    "        \n",
    "def delete_message(index):\n",
    "    if 0 <= index < len(konnos_chat_history.messages):\n",
    "        del konnos_chat_history.messages[index]\n",
    "        print(f\"Deleted message at index {index}\")\n",
    "\n",
    "def delete_all_messages():\n",
    "    konnos_chat_history.messages.clear()\n",
    "    print(\"All messages deleted.\")\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks(css=\".small-button { max-width: 100px; display: inline-block !important; margin-right: 10px; }\") as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    message_input = gr.Textbox(placeholder=\"Type your message here...\", label=\"You\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            save_button = gr.Button(\"Save\", variant=\"primary\")\n",
    "        with gr.Column(scale=1):\n",
    "            save_as_button = gr.Button(\"Save As\", variant=\"secondary\")\n",
    "        with gr.Column(scale=1):\n",
    "            open_file = gr.File(label=\"Open Chat (.pkl)\", type=\"filepath\", file_count=\"single\")\n",
    "        with gr.Column(scale=1):\n",
    "            delete_all_button = gr.Button(\"Delete All\", variant=\"warning\")\n",
    "\n",
    "    async def respond(message, chat_history):\n",
    "        print(f\"Responding to user message: {message}\")\n",
    "        bot_response = \"\".join([chunk async for chunk in interactive_conversation_stream(message)]).strip()\n",
    "        print(f\"Bot response: {bot_response}\")\n",
    "        chat_history.append((message, bot_response))\n",
    "        return chat_history, \"\"\n",
    "\n",
    "    def trigger_save_as_dialog():\n",
    "        return gr.File(label=\"Save As\", type=\"filepath\", file_count=\"single\")\n",
    "\n",
    "    def handle_save_as_click(file):\n",
    "        if file:\n",
    "            save_chat_history_as(file.name)\n",
    "        return gr.update()\n",
    "\n",
    "    def handle_save_click():\n",
    "        global current_file_path\n",
    "        if current_file_path is None:\n",
    "            # Trigger 'Save As' dialog if no file path is set\n",
    "            return trigger_save_as_dialog()\n",
    "        else:\n",
    "            save_chat_history()\n",
    "        return gr.update()\n",
    "\n",
    "    def handle_open_file(file):\n",
    "        if file:\n",
    "            chat_history = load_chat_history(file.name)\n",
    "            return chat_history\n",
    "        return []\n",
    "\n",
    "    def handle_delete_all_click():\n",
    "        delete_all_messages()\n",
    "        return gr.update()\n",
    "\n",
    "    save_button.click(fn=handle_save_click, inputs=[], outputs=[])\n",
    "    save_as_button.click(fn=trigger_save_as_dialog, inputs=[], outputs=[save_as_button])\n",
    "    #save_as_button.upload(fn=handle_save_as_click, inputs=save_as_button, outputs=[])\n",
    "    open_file.upload(fn=handle_open_file, inputs=open_file, outputs=[chatbot])\n",
    "    delete_all_button.click(fn=handle_delete_all_click, inputs=[], outputs=[])\n",
    "\n",
    "    message_input.submit(respond, [message_input, chatbot], [chatbot, message_input])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EventListener._setup.<locals>.event_trigger() got an unexpected keyword argument 'live'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 64\u001b[0m\n\u001b[1;32m     60\u001b[0m file_picker \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mFile(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatei auswählen\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m progress \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mMarkdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, show_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 64\u001b[0m \u001b[43msubmit_button\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchatbox\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mchatbox\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m save_button\u001b[38;5;241m.\u001b[39mclick(save_chat, [], progress)\n\u001b[1;32m     66\u001b[0m save_as_button\u001b[38;5;241m.\u001b[39mclick(save_chat_as, [file_picker], progress)\n",
      "\u001b[0;31mTypeError\u001b[0m: EventListener._setup.<locals>.event_trigger() got an unexpected keyword argument 'live'"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from azure.ai.openai import OpenAIClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "# Azure OpenAI und LangChain initialisieren\n",
    "azure_api_key = 'YOUR_AZURE_API_KEY'\n",
    "azure_api_endpoint = 'YOUR_AZURE_API_ENDPOINT'\n",
    "client = OpenAIClient(endpoint=azure_api_endpoint, credential=AzureKeyCredential(azure_api_key))\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def query_openai(prompt):\n",
    "    response = client.completions.create(\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        temperature=0.9,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "def stream_response(prompt):\n",
    "    response_text = query_openai(prompt)\n",
    "    for i in range(1, len(response_text)+1):\n",
    "        yield response_text[:i]\n",
    "        sleep(0.05)\n",
    "\n",
    "def chat(input_text, chat_history):\n",
    "    chat_history.append((\"User\", input_text))\n",
    "    response_stream = stream_response(input_text)\n",
    "    response_text = \"\"\n",
    "\n",
    "    for chunk in response_stream:\n",
    "        response_text = chunk\n",
    "        yield chat_history + [(\"AI\", response_text)], response_text\n",
    "\n",
    "def save_chat():\n",
    "    with open('chat_history.json', 'w') as f:\n",
    "        json.dump(chat_history, f)\n",
    "    return \"Chat gespeichert!\"\n",
    "\n",
    "def save_chat_as(file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(chat_history, f)\n",
    "    return f\"Chat gespeichert als: {file_path}\"\n",
    "\n",
    "def open_chat(file_path):\n",
    "    global chat_history\n",
    "    with open(file_path, 'r') as f:\n",
    "        chat_history = json.load(f)\n",
    "    return chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbox = gr.Chatbot(label=\"Chatbot mit Azure OpenAI und LangChain\")\n",
    "    user_input = gr.Textbox(label=\"Deine Nachricht\")\n",
    "    submit_button = gr.Button(\"Senden\")\n",
    "    save_button = gr.Button(\"Speichern\")\n",
    "    save_as_button = gr.Button(\"Speichern als\")\n",
    "    open_button = gr.Button(\"Öffnen\")\n",
    "    file_picker = gr.File(label=\"Datei auswählen\", type=\"file\")\n",
    "\n",
    "    output_text = gr.Textbox(label=\"AI Antwort\")\n",
    "    progress = gr.HTML(\"\")\n",
    "\n",
    "    submit_button.click(chat, [user_input, chatbox], [chatbox, output_text])\n",
    "    save_button.click(save_chat, [], progress)\n",
    "    save_as_button.click(save_chat_as, [file_picker], progress)\n",
    "    open_button.click(open_chat, [file_picker], chatbox)\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
