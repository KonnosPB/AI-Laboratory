{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment: Anwendung von Azure-Open AI in Verbindung mit Langchain.\n",
    "\n",
    "Bei der Nutzung von Azure-Open AI ist es erforderlich, sicherheitskritische Informationen wie API-Token zu verwenden. Um deren Sicherheit zu gewährleisten und eine Speicherung in Dateien zu vermeiden, empfiehlt sich die Verwendung von Umgebungsvariablen. Open AI stellt diese bereits vordefiniert bereit.\n",
    "\n",
    "``` bash\n",
    "# The API version you want to use: set this to `2023-12-01-preview` for the released version.\n",
    "export OPENAI_API_VERSION=2024-02-15-preview\n",
    "# The base URL for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource.\n",
    "export AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com\n",
    "# The API key for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource.\n",
    "export AZURE_OPENAI_API_KEY=<your Azure OpenAI API key>\n",
    "``` \n",
    "\n",
    "Um die ständige Neueingabe dieser Informationen zu vermeiden, können diese Befehle in die Datei ~/.bashrc eingefügt werden.\n",
    "\n",
    "Quellen:\n",
    "- https://python.langchain.com/docs/integrations/llms/azure_openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_deployment = \"gpt-4\"\n",
    ")\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=\"Verfasse eine 50 Wörter umfassende Vorlesegeschichte für Kinder, in der es um eine kleine Kartoffel namens Pellemann geht, die einen Hügel hinunterrollt, um ihre Freunde zu suchen.\"\n",
    ")\n",
    "model.invoke([message])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: AzureOpenAI mit Streaming-Function\n",
    "Manchmal kann die Datenmenge so groß sein, dass die Verarbeitung und Ausgabe der Ergebnisse erhebliche Zeit in Anspruch nimmt. \n",
    "Für solche Situationen ist es vorteilhaft, bereits empfangene und verarbeitete Daten fortlaufend auszugeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einmal da war eine kleine Kartoffel namens Pellemann. Eines Tages kullerte er den Hügel runter, hinaus ins weite Feld. Er hüpfte vorbei an bunten Blumen und summenden Bienen. Am Fuße des Hügels fand er endlich seine Freunde. \"Hallo, Pellemann!\" riefen sie und spielten den ganzen Tag zusammen."
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.callbacks.base import BaseCallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_deployment = \"gpt-4\",\n",
    "    streaming=True,\n",
    "    callback_manager=BaseCallbackManager([\n",
    "        StreamingStdOutCallbackHandler()]),\n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    message = HumanMessage(\n",
    "        content=\"Verfasse eine 50 Wörter umfassende Vorlesegeschichte für Kinder, in der es um eine kleine Kartoffel namens Pellemann geht, die einen Hügel hinunterrollt, um ihre Freunde zu suchen.\"\n",
    "    )\n",
    "    model.invoke([message])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expereriment AzureOpenAI mit Streaming und Token-Zählung\n",
    "\n",
    "In Situationen mit umfangreichen Datenmengen kann die Verarbeitungs- und Ausgabezeit der Ergebnisse erheblich sein. \n",
    "Um dies zu umgehen, ist es zweckmäßig, die bereits verarbeiteten Daten kontinuierlich auszugeben. \n",
    "Darüber hinaus beinhaltet dieses Experiment eine Funktion, die die verarbeiteten Tokens zählt und diese Information ebenfalls ausgibt.\n",
    "Dies wird durch die Vererbung der BaseCallbackHandler-Klasse ermöglicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einmal war eine kleine Kartoffel, namens Pellemann, die allein auf einem Hügel lebte. Eines Tages beschloss er, seine Freunde zu suchen. Also kullerte er tapfer den Hügel hinunter. Er lachte, hüpfte und rollte, bis er schließlich seine Freunde fand. Sie spielten glücklich den ganzen Tag.\n",
      "Anzahl token: 90\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.callbacks.base import BaseCallbackManager, BaseCallbackHandler\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.outputs.llm_result import LLMResult\n",
    "\n",
    "class MyCustomHandler(BaseCallbackHandler):\n",
    "    tokenCount = 0  \n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        self.tokenCount += 1\n",
    "        print(token, end=\"\")\n",
    "\n",
    "    def on_llm_end(self, response: LLMResult, **kwargs) -> None:        \n",
    "        print(f\"\\nAnzahl token: {self.tokenCount}\")\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_deployment = \"gpt-4\",\n",
    "    streaming=True,\n",
    "    callback_manager=BaseCallbackManager([\n",
    "        MyCustomHandler()]),\n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    message = HumanMessage(\n",
    "        content=\"Verfasse eine 50 Wörter umfassende Vorlesegeschichte für Kinder, in der es um eine kleine Kartoffel namens Pellemann geht, die einen Hügel hinunterrollt, um ihre Freunde zu suchen.\"\n",
    "    )\n",
    "    model.invoke([message])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
