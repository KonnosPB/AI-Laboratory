{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment: Anwendung von Azure-Open AI in Verbindung mit Langchain.\n",
    "\n",
    "Bei der Nutzung von Azure-Open AI ist es erforderlich, sicherheitskritische Informationen wie API-Token zu verwenden. Um deren Sicherheit zu gewährleisten und eine Speicherung in Dateien zu vermeiden, empfiehlt sich die Verwendung von Umgebungsvariablen. Open AI stellt diese bereits vordefiniert bereit.\n",
    "\n",
    "``` bash\n",
    "# The API version you want to use: set this to `2023-12-01-preview` for the released version.\n",
    "export OPENAI_API_VERSION=2024-02-15-preview\n",
    "# The base URL for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource.\n",
    "export AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com\n",
    "# The API key for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource.\n",
    "export AZURE_OPENAI_API_KEY=<your Azure OpenAI API key>\n",
    "``` \n",
    "\n",
    "Um die ständige Neueingabe dieser Informationen zu vermeiden, können diese Befehle in die Datei ~/.bashrc eingefügt werden.\n",
    "\n",
    "Quellen:\n",
    "- https://python.langchain.com/docs/integrations/llms/azure_openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Pellemann, die kleine Kartoffel, voller Mut und Tapferkeit, rollte einen großen Hügel hinunter. Er hüpfte und hoppelte, auf der Suche nach seinen Freunden. Oben auf dem Hügel sagte er \"Auf Wiedersehen\" zu seiner Heimat und lächelte, voll freudiger Erwartung auf das Abenteuer, das vor ihm lag.', response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 61, 'total_tokens': 150}, 'model_name': 'gpt-4-32k', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-4cb47dbb-031d-48dd-b4e0-699fe4266ba0-0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_deployment = \"gpt-4-32k\"\n",
    ")\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=\"Verfasse eine 50 Wörter umfassende Vorlesegeschichte für Kinder, in der es um eine kleine Kartoffel namens Pellemann geht, die einen Hügel hinunterrollt, um ihre Freunde zu suchen.\"\n",
    ")\n",
    "model.invoke([message])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: AzureOpenAI mit Streaming-Function\n",
    "Manchmal kann die Datenmenge so groß sein, dass die Verarbeitung und Ausgabe der Ergebnisse erhebliche Zeit in Anspruch nimmt. \n",
    "Für solche Situationen ist es vorteilhaft, bereits empfangene und verarbeitete Daten fortlaufend auszugeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pellemann, die kleine Kartoffel, rollte fröhlich den Hügel hinunter. Er war auf der Suche nach seinen Freunden. Er rief: \"Wo seid ihr?\" Da hörte er ein Kichern. Hinter einem Stein, da saßen sie - die anderen Kartoffelkinder. Gemeinsam spielten sie den ganzen Tag und hatten viel Spaß."
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.callbacks.base import BaseCallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_deployment = \"gpt-4\",\n",
    "    streaming=True,\n",
    "    callback_manager=BaseCallbackManager([\n",
    "        StreamingStdOutCallbackHandler()]),\n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    message = HumanMessage(\n",
    "        content=\"Verfasse eine 50 Wörter umfassende Vorlesegeschichte für Kinder, in der es um eine kleine Kartoffel namens Pellemann geht, die einen Hügel hinunterrollt, um ihre Freunde zu suchen.\"\n",
    "    )\n",
    "    model.invoke([message])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expereriment AzureOpenAI mit Streaming und Token-Zählung\n",
    "\n",
    "In Situationen mit umfangreichen Datenmengen kann die Verarbeitungs- und Ausgabezeit der Ergebnisse erheblich sein. \n",
    "Um dies zu umgehen, ist es zweckmäßig, die bereits verarbeiteten Daten kontinuierlich auszugeben. \n",
    "Darüber hinaus beinhaltet dieses Experiment eine Funktion, die die verarbeiteten Tokens zählt und diese Information ebenfalls ausgibt.\n",
    "Dies wird durch die Vererbung der BaseCallbackHandler-Klasse ermöglicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einmal lebte eine kleine Kartoffel namens Pellemann. Eines Tages rollte er einen Hügel hinunter, auf der Suche nach seinen Freunden. Er hüpfte über Steine, glitt durch Gras und lachte dabei fröhlich. Am Fuße des Hügels fand er schließlich seine Freunde und spielte den ganzen Tag glücklich mit ihnen.\n",
      "Anzahl token: 91\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.callbacks.base import BaseCallbackManager, BaseCallbackHandler\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.outputs.llm_result import LLMResult\n",
    "\n",
    "class MyCustomHandler(BaseCallbackHandler):\n",
    "    tokenCount = 0  \n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        self.tokenCount += 1\n",
    "        print(token, end=\"\")\n",
    "\n",
    "    def on_llm_end(self, response: LLMResult, **kwargs) -> None:        \n",
    "        print(f\"\\nAnzahl token: {self.tokenCount}\")\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_deployment = \"gpt-4\",\n",
    "    streaming=True,\n",
    "    callback_manager=BaseCallbackManager([\n",
    "        MyCustomHandler()]),\n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    message = HumanMessage(\n",
    "        content=\"Verfasse eine 50 Wörter umfassende Vorlesegeschichte für Kinder, in der es um eine kleine Kartoffel namens Pellemann geht, die einen Hügel hinunterrollt, um ihre Freunde zu suchen.\"\n",
    "    )\n",
    "    model.invoke([message])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
