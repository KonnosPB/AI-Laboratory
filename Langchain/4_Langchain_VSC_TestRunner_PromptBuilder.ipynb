{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using deployment name: gpt-4o\n",
      "Prompt template created.\n",
      "Chat history initialized.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Button' object has no attribute 'upload'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 207\u001b[0m\n\u001b[1;32m    205\u001b[0m save_button\u001b[38;5;241m.\u001b[39mclick(fn\u001b[38;5;241m=\u001b[39mhandle_save_click, inputs\u001b[38;5;241m=\u001b[39m[], outputs\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    206\u001b[0m save_as_button\u001b[38;5;241m.\u001b[39mclick(fn\u001b[38;5;241m=\u001b[39mtrigger_save_as_dialog, inputs\u001b[38;5;241m=\u001b[39m[], outputs\u001b[38;5;241m=\u001b[39m[save_as_button])\n\u001b[0;32m--> 207\u001b[0m \u001b[43msave_as_button\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload\u001b[49m(fn\u001b[38;5;241m=\u001b[39mhandle_save_as_click, inputs\u001b[38;5;241m=\u001b[39msave_as_button, outputs\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    208\u001b[0m open_file\u001b[38;5;241m.\u001b[39mupload(fn\u001b[38;5;241m=\u001b[39mhandle_open_file, inputs\u001b[38;5;241m=\u001b[39mopen_file, outputs\u001b[38;5;241m=\u001b[39m[chatbot])\n\u001b[1;32m    209\u001b[0m delete_all_button\u001b[38;5;241m.\u001b[39mclick(fn\u001b[38;5;241m=\u001b[39mhandle_delete_all_click, inputs\u001b[38;5;241m=\u001b[39m[], outputs\u001b[38;5;241m=\u001b[39m[])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Button' object has no attribute 'upload'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import asyncio\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "import gradio as gr\n",
    "\n",
    "# Check environment variable\n",
    "deployment_name = os.getenv(\"OPENAI_API_DEPLOYMENT_NAME\")\n",
    "if not deployment_name:\n",
    "    raise ValueError(\"OPENAI_API_DEPLOYMENT_NAME environment variable is not set.\")\n",
    "print(f\"Using deployment name: {deployment_name}\")\n",
    "\n",
    "# Initialize the model\n",
    "model = AzureChatOpenAI(deployment_name=deployment_name)\n",
    "\n",
    "# Function to read file contents\n",
    "def get_file_content(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filepath} not found.\")\n",
    "        return \"\"\n",
    "\n",
    "# Manage session history\n",
    "store = {}\n",
    "def get_session_history(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Function to get system prompt\n",
    "def get_system_prompt():\n",
    "    return get_file_content('./SystemPrompt-VSC-BusinesCentral-TestRunner.txt')\n",
    "\n",
    "file_paths = {\n",
    "    'al_endpoint': '../BusinessCentral-AL-Test-Runner-App/src/codeunit/WebApi.Codeunit.al',\n",
    "    'package_json': '../VSC-BusinessCentral-Test-Runner/package.json',\n",
    "    'apiclient_ts': '../VSC-BusinessCentral-Test-Runner/src/apiClient.ts',\n",
    "    'project_ts': '../VSC-BusinessCentral-Test-Runner/src/project.ts',\n",
    "    'testrunner_ts': '../VSC-BusinessCentral-Test-Runner/src/testRunner.ts',\n",
    "    'testviewproviders_ts': '../VSC-BusinessCentral-Test-Runner/src/testViewProviders.ts',\n",
    "    'extension_ts': '../VSC-BusinessCentral-Test-Runner/src/extension.ts',\n",
    "}\n",
    "\n",
    "file_contents = {key: get_file_content(path) for key, path in file_paths.items()}\n",
    "systemprompt = get_system_prompt()\n",
    "\n",
    "# Escape the curly braces\n",
    "def escape_curly_braces(s):\n",
    "    return s.replace('{', '{{').replace('}', '}}')\n",
    "\n",
    "system_message = SystemMessage(content=systemprompt)\n",
    "file_content_messages = [\n",
    "    SystemMessage(content=f\"#### This is the content of {key}: {escape_curly_braces(file_contents[key])}\\n---\")\n",
    "    for key in file_contents\n",
    "]\n",
    "user_message_template = HumanMessage(content=\"{input}\")\n",
    "messages = [system_message, *file_content_messages, user_message_template]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "print(\"Prompt template created.\")\n",
    "\n",
    "konnos_chat_history = get_session_history(\"default\")\n",
    "current_file_path = None\n",
    "print(\"Chat history initialized.\")\n",
    "\n",
    "def save_chat_history_as(file_path):\n",
    "    global current_file_path\n",
    "    try:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(konnos_chat_history.messages, f)\n",
    "        print(f\"Chat history saved as: {file_path}\")\n",
    "        current_file_path = file_path\n",
    "        return file_path\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save chat history: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_chat_history():\n",
    "    global current_file_path\n",
    "    if current_file_path is None:\n",
    "        return None\n",
    "    try:\n",
    "        with open(current_file_path, 'wb') as f:\n",
    "            pickle.dump(konnos_chat_history.messages, f)\n",
    "        print(f\"Chat history saved to: {current_file_path}\")\n",
    "        return current_file_path\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save chat history: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_chat_history(file_path):\n",
    "    global konnos_chat_history, current_file_path\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            konnos_chat_history.messages = pickle.load(f)\n",
    "        current_file_path = file_path\n",
    "        chat_entries = [(msg.content if isinstance(msg, HumanMessage) else \"\", msg.content if isinstance(msg, AIMessage) else \"\") for msg in konnos_chat_history.messages]\n",
    "        print(f\"Chat history loaded from: {file_path}\")\n",
    "        return chat_entries\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load chat history: {e}\")\n",
    "        return []\n",
    "\n",
    "async def converse(user_input):\n",
    "    print(f\"User input received: {user_input}\")\n",
    "    chat_history_list = konnos_chat_history.messages\n",
    "\n",
    "    formatted_prompt = prompt_template.format(\n",
    "        chat_history=chat_history_list,\n",
    "        input=user_input,\n",
    "        **file_contents\n",
    "    )\n",
    "\n",
    "    konnos_chat_history.add_message(HumanMessage(content=user_input))\n",
    "    print(\"Human message added to history.\")\n",
    "    \n",
    "    response = await asyncio.to_thread(model.invoke, formatted_prompt)\n",
    "    konnos_chat_history.add_message(AIMessage(content=response.content))\n",
    "    print(\"AI message added to history.\")\n",
    "    return response.content\n",
    "\n",
    "async def interactive_conversation_stream(user_input):\n",
    "    chat_history_list = konnos_chat_history.messages\n",
    "\n",
    "    formatted_prompt = prompt_template.format(\n",
    "        chat_history=chat_history_list,\n",
    "        input=user_input,\n",
    "        **file_contents\n",
    "    )\n",
    "\n",
    "    konnos_chat_history.add_message(HumanMessage(content=user_input))\n",
    "    print(\"Human message added to history.\")\n",
    "\n",
    "    response = await asyncio.to_thread(model.invoke, formatted_prompt)\n",
    "\n",
    "    konnos_chat_history.add_message(AIMessage(content=response.content))\n",
    "    print(\"AI message added to history.\")\n",
    "    \n",
    "    for char in response.content:\n",
    "        yield char\n",
    "        \n",
    "def delete_message(index):\n",
    "    if 0 <= index < len(konnos_chat_history.messages):\n",
    "        del konnos_chat_history.messages[index]\n",
    "        print(f\"Deleted message at index {index}\")\n",
    "\n",
    "def delete_all_messages():\n",
    "    konnos_chat_history.messages.clear()\n",
    "    print(\"All messages deleted.\")\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks(css=\".small-button { max-width: 100px; display: inline-block !important; margin-right: 10px; }\") as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    message_input = gr.Textbox(placeholder=\"Type your message here...\", label=\"You\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            save_button = gr.Button(\"Save\", variant=\"primary\")\n",
    "        with gr.Column(scale=1):\n",
    "            save_as_button = gr.Button(\"Save As\", variant=\"secondary\")\n",
    "        with gr.Column(scale=1):\n",
    "            open_file = gr.File(label=\"Open Chat (.pkl)\", type=\"filepath\", file_count=\"single\")\n",
    "        with gr.Column(scale=1):\n",
    "            delete_all_button = gr.Button(\"Delete All\", variant=\"warning\")\n",
    "\n",
    "    async def respond(message, chat_history):\n",
    "        print(f\"Responding to user message: {message}\")\n",
    "        bot_response = \"\".join([chunk async for chunk in interactive_conversation_stream(message)]).strip()\n",
    "        print(f\"Bot response: {bot_response}\")\n",
    "        chat_history.append((message, bot_response))\n",
    "        return chat_history, \"\"\n",
    "\n",
    "    def trigger_save_as_dialog():\n",
    "        return gr.File(label=\"Save As\", type=\"filepath\", file_count=\"single\")\n",
    "\n",
    "    def handle_save_as_click(file):\n",
    "        if file:\n",
    "            save_chat_history_as(file.name)\n",
    "        return gr.update()\n",
    "\n",
    "    def handle_save_click():\n",
    "        global current_file_path\n",
    "        if current_file_path is None:\n",
    "            # Trigger 'Save As' dialog if no file path is set\n",
    "            return trigger_save_as_dialog()\n",
    "        else:\n",
    "            save_chat_history()\n",
    "        return gr.update()\n",
    "\n",
    "    def handle_open_file(file):\n",
    "        if file:\n",
    "            chat_history = load_chat_history(file.name)\n",
    "            return chat_history\n",
    "        return []\n",
    "\n",
    "    def handle_delete_all_click():\n",
    "        delete_all_messages()\n",
    "        return gr.update()\n",
    "\n",
    "    save_button.click(fn=handle_save_click, inputs=[], outputs=[])\n",
    "    save_as_button.click(fn=trigger_save_as_dialog, inputs=[], outputs=[save_as_button])\n",
    "    #save_as_button.upload(fn=handle_save_as_click, inputs=save_as_button, outputs=[])\n",
    "    open_file.upload(fn=handle_open_file, inputs=open_file, outputs=[chatbot])\n",
    "    delete_all_button.click(fn=handle_delete_all_click, inputs=[], outputs=[])\n",
    "\n",
    "    message_input.submit(respond, [message_input, chatbot], [chatbot, message_input])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio Interface gestartet.\n",
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import openai\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# Initialisiere LangChain und Chat-Modell\n",
    "llm = AzureChatOpenAI(model=\"gpt-4o\", api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"))\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "# Lade die erste Nachricht aus der Datei\n",
    "with open('../Prompts/SystemPrompt-VSC-BusinesCentral-TestRunner.txt', 'r', encoding='utf-8') as file:\n",
    "    system_prompt = file.read()\n",
    "history.add_message(SystemMessage(content=system_prompt))\n",
    "\n",
    "# Lade weitere Nachrichten aus den angegebenen Dateien\n",
    "file_paths = [\n",
    "    '../../BusinessCentral-AL-Test-Runner-App/src/codeunit/WebApi.Codeunit.al',\n",
    "    '../../VSC-BusinessCentral-Test-Runner/package.json',\n",
    "    '../../VSC-BusinessCentral-Test-Runner/src/apiClient.ts',\n",
    "    '../../VSC-BusinessCentral-Test-Runner/src/project.ts',\n",
    "    '../../VSC-BusinessCentral-Test-Runner/src/testRunner.ts',\n",
    "    '../../VSC-BusinessCentral-Test-Runner/src/testViewProviders.ts',\n",
    "    '../../VSC-BusinessCentral-Test-Runner/src/extension.ts'\n",
    "]\n",
    "\n",
    "for path in file_paths:\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    history.add_message(HumanMessage(content=content))\n",
    "\n",
    "# Funktion zum Speichern der Chat-Historie\n",
    "def save_chat_history(history, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        for message in history.messages:\n",
    "            role = \"system\" if isinstance(message, SystemMessage) else \"user\" if isinstance(message, HumanMessage) else \"assistant\"\n",
    "            file.write(f\"{role}: {message.content}\\n\")\n",
    "    print(\"Chat-Historie gespeichert.\")\n",
    "\n",
    "# Funktion zum Laden der Chat-Historie\n",
    "def load_chat_history(filename):\n",
    "    history = ChatMessageHistory()\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            role, content = line.split(\": \", 1)\n",
    "            if role == \"user\":\n",
    "                history.add_message(HumanMessage(content=content.strip()))\n",
    "            elif role == \"assistant\":\n",
    "                history.add_message(AIMessage(content=content.strip()))\n",
    "            elif role == \"system\":\n",
    "                history.add_message(SystemMessage(content=content.strip()))\n",
    "    print(\"Chat-Historie geladen.\")\n",
    "    return history\n",
    "\n",
    "# Gradio Interface\n",
    "def chat_interface(user_input, history):\n",
    "    history.add_message(HumanMessage(content=user_input))\n",
    "    response = llm(history.messages)\n",
    "    response_text = response.content  # Extrahiere den Textinhalt aus der Antwort\n",
    "    history.add_message(AIMessage(content=response_text))\n",
    "    return [(msg.__class__.__name__.lower(), msg.content) for msg in history.messages], history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Chatbot mit LangChain, Azure Open AI und Gradio\")\n",
    "    chat_history = gr.State(history)\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            chatbox = gr.Chatbot()\n",
    "            user_input = gr.Textbox()\n",
    "            save_button = gr.Button(\"Chat-Historie speichern\")\n",
    "            load_button = gr.Button(\"Chat-Historie laden\")\n",
    "            file_input = gr.File(label=\"Chat-Historie Datei\", type=\"filepath\")\n",
    "            file_output = gr.File(label=\"Speichern unter\", type=\"filepath\")\n",
    "    \n",
    "    user_input.submit(chat_interface, [user_input, chat_history], [chatbox, chat_history])\n",
    "    save_button.click(save_chat_history, [chat_history, file_output])\n",
    "    load_button.click(load_chat_history, [file_input], chat_history)\n",
    "\n",
    "    print(\"Gradio Interface gestartet.\")\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
