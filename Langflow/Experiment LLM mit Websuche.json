{"id":"80a67a34-1a26-4ded-a390-1afbfeeea1c4","data":{"nodes":[{"id":"BingSearchAPIWrapper-J010B","type":"genericNode","position":{"x":738.224777325461,"y":967.1741758569922},"data":{"type":"BingSearchAPIWrapper","node":{"template":{"bing_search_url":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bing_search_url","display_name":"Bing Search URL","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"https://www.amazon.de"},"bing_subscription_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"bing_subscription_key","display_name":"Bing Subscription Key","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"# Assuming `BingSearchAPIWrapper` is a class that exists in the context\n# and has the appropriate methods and attributes.\n# We need to make sure this class is importable from the context where this code will be running.\nfrom langchain_community.utilities.bing_search import BingSearchAPIWrapper\n\nfrom langflow.custom import CustomComponent\n\n\nclass BingSearchAPIWrapperComponent(CustomComponent):\n    display_name = \"BingSearchAPIWrapper\"\n    description = \"Wrapper for Bing Search API.\"\n\n    def build_config(self):\n        return {\n            \"bing_search_url\": {\"display_name\": \"Bing Search URL\"},\n            \"bing_subscription_key\": {\n                \"display_name\": \"Bing Subscription Key\",\n                \"password\": True,\n            },\n            \"k\": {\"display_name\": \"Number of results\", \"advanced\": True},\n            # 'k' is not included as it is not shown (show=False)\n        }\n\n    def build(\n        self,\n        bing_search_url: str,\n        bing_subscription_key: str,\n        k: int = 10,\n    ) -> BingSearchAPIWrapper:\n        # 'k' has a default value and is not shown (show=False), so it is hardcoded here\n        return BingSearchAPIWrapper(bing_search_url=bing_search_url, bing_subscription_key=bing_subscription_key, k=k)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"k":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":10,"fileTypes":[],"file_path":"","password":false,"name":"k","display_name":"Number of results","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Wrapper for Bing Search API.","base_classes":["BingSearchAPIWrapper"],"display_name":"BingSearchAPIWrapper","documentation":"","custom_fields":{"bing_search_url":null,"bing_subscription_key":null,"k":null},"output_types":["BingSearchAPIWrapper"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"BingSearchAPIWrapper-J010B"},"selected":false,"width":384,"height":391,"positionAbsolute":{"x":738.224777325461,"y":967.1741758569922},"dragging":false},{"id":"MemoryComponent-SExyL","type":"genericNode","position":{"x":185,"y":-3.899993896484375},"data":{"type":"MemoryComponent","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.memory.memory import BaseMemoryComponent\nfrom langflow.field_typing import Text\nfrom langflow.helpers.record import messages_to_text\nfrom langflow.memory import get_messages\nfrom langflow.schema.message import Message\n\n\nclass MemoryComponent(BaseMemoryComponent):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages given a specific Session ID.\"\n    beta: bool = True\n    icon = \"history\"\n\n    def build_config(self):\n        return {\n            \"sender\": {\n                \"options\": [\"Machine\", \"User\", \"Machine and User\"],\n                \"display_name\": \"Sender Type\",\n            },\n            \"sender_name\": {\"display_name\": \"Sender Name\", \"advanced\": True},\n            \"n_messages\": {\n                \"display_name\": \"Number of Messages\",\n                \"info\": \"Number of messages to retrieve.\",\n            },\n            \"session_id\": {\n                \"display_name\": \"Session ID\",\n                \"info\": \"Session ID of the chat history.\",\n                \"input_types\": [\"Text\"],\n            },\n            \"order\": {\n                \"options\": [\"Ascending\", \"Descending\"],\n                \"display_name\": \"Order\",\n                \"info\": \"Order of the messages.\",\n                \"advanced\": True,\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def get_messages(self, **kwargs) -> list[Message]:\n        # Validate kwargs by checking if it contains the correct keys\n        if \"sender\" not in kwargs:\n            kwargs[\"sender\"] = None\n        if \"sender_name\" not in kwargs:\n            kwargs[\"sender_name\"] = None\n        if \"session_id\" not in kwargs:\n            kwargs[\"session_id\"] = None\n        if \"limit\" not in kwargs:\n            kwargs[\"limit\"] = 5\n        if \"order\" not in kwargs:\n            kwargs[\"order\"] = \"Descending\"\n\n        kwargs[\"order\"] = \"DESC\" if kwargs[\"order\"] == \"Descending\" else \"ASC\"\n        if kwargs[\"sender\"] == \"Machine and User\":\n            kwargs[\"sender\"] = None\n        return get_messages(**kwargs)\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine and User\",\n        sender_name: Optional[str] = None,\n        session_id: Optional[str] = None,\n        n_messages: int = 5,\n        order: Optional[str] = \"Descending\",\n        record_template: Optional[str] = \"{sender_name}: {text}\",\n    ) -> Text:\n        messages = self.get_messages(\n            sender=sender,\n            sender_name=sender_name,\n            session_id=session_id,\n            limit=n_messages,\n            order=order,\n        )\n        messages_str = messages_to_text(template=record_template or \"\", messages=messages)\n        self.status = messages_str\n        return messages_str\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"n_messages":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"10","fileTypes":[],"file_path":"","password":false,"name":"n_messages","display_name":"Number of Messages","advanced":false,"dynamic":false,"info":"Number of messages to retrieve.","load_from_db":false,"title_case":false},"order":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Descending","fileTypes":[],"file_path":"","password":false,"options":["Ascending","Descending"],"name":"order","display_name":"Order","advanced":true,"dynamic":false,"info":"Order of the messages.","load_from_db":false,"title_case":false,"input_types":["Text"]},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"{sender_name}: {text}","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine and User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User","Machine and User"],"name":"sender","display_name":"Sender Type","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"User"},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":false,"input_types":["Text"],"dynamic":false,"info":"Session ID of the chat history.","load_from_db":false,"title_case":false,"value":""},"_type":"CustomComponent"},"description":"Retrieves stored chat messages given a specific Session ID.","icon":"history","base_classes":["object","str","Text"],"display_name":"Chat History","documentation":"","custom_fields":{"sender":null,"sender_name":null,"session_id":null,"n_messages":null,"order":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":true},"id":"MemoryComponent-SExyL"},"selected":false,"width":384,"height":599,"dragging":false,"positionAbsolute":{"x":185,"y":-3.899993896484375}},{"id":"AzureOpenAIModel-Bbibi","type":"genericNode","position":{"x":1226,"y":168.10000610351562},"data":{"type":"AzureOpenAIModel","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"input_types":["Text","Record","Prompt"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"api_key","display_name":"API Key","advanced":false,"dynamic":false,"info":"","load_from_db":true,"title_case":false,"input_types":["Text"],"value":""},"api_version":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"value":"2023-12-01-preview","fileTypes":[],"file_path":"","password":false,"options":["2023-03-15-preview","2023-05-15","2023-06-01-preview","2023-07-01-preview","2023-08-01-preview","2023-09-01-preview","2023-12-01-preview"],"name":"api_version","display_name":"API Version","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"azure_deployment":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"azure_deployment","display_name":"Deployment Name","advanced":false,"dynamic":false,"info":"","load_from_db":true,"title_case":false,"input_types":["Text"],"value":"AZURE_OPENAI_DEPLOYMENT_NAME"},"azure_endpoint":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"azure_endpoint","display_name":"Azure Endpoint","advanced":false,"dynamic":false,"info":"Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`","load_from_db":true,"title_case":false,"input_types":["Text"],"value":"AZURE_OPENAI_ENDPOINT"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_openai import AzureChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Text\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n\n    field_order = [\n        \"model\",\n        \"azure_endpoint\",\n        \"azure_deployment\",\n        \"api_version\",\n        \"api_key\",\n        \"temperature\",\n        \"max_tokens\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    AZURE_OPENAI_MODELS = [\n        \"gpt-35-turbo\",\n        \"gpt-35-turbo-16k\",\n        \"gpt-35-turbo-instruct\",\n        \"gpt-4\",\n        \"gpt-4-32k\",\n        \"gpt-4-vision\",\n    ]\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n        \"2023-09-01-preview\",\n        \"2023-12-01-preview\",\n    ]\n\n    def build_config(self):\n        return {\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": self.AZURE_OPENAI_MODELS[0],\n                \"options\": self.AZURE_OPENAI_MODELS,\n            },\n            \"azure_endpoint\": {\n                \"display_name\": \"Azure Endpoint\",\n                \"info\": \"Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`\",\n            },\n            \"azure_deployment\": {\n                \"display_name\": \"Deployment Name\",\n            },\n            \"api_version\": {\n                \"display_name\": \"API Version\",\n                \"options\": self.AZURE_OPENAI_API_VERSIONS,\n                \"value\": self.AZURE_OPENAI_API_VERSIONS[-1],\n                \"advanced\": True,\n            },\n            \"api_key\": {\"display_name\": \"API Key\", \"password\": True},\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"value\": 0.7,\n            },\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"advanced\": True,\n                \"info\": \"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            },\n            \"code\": {\"show\": False},\n            \"input_value\": {\"display_name\": \"Input\", \"input_types\": [\"Text\", \"Record\", \"Prompt\"]},\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        model: str,\n        azure_endpoint: str,\n        input_value: Text,\n        azure_deployment: str,\n        api_version: str,\n        api_key: str,\n        temperature: float,\n        system_message: Optional[str] = None,\n        max_tokens: Optional[int] = 1000,\n        stream: bool = False,\n    ) -> Text:\n        if api_key:\n            secret_api_key = SecretStr(api_key)\n        else:\n            secret_api_key = None\n        try:\n            output = AzureChatOpenAI(\n                model=model,\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=secret_api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to AzureOpenAI API.\") from e\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":1000,"fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","load_from_db":false,"title_case":false},"model":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"value":"gpt-4-32k","fileTypes":[],"file_path":"","password":false,"options":["gpt-35-turbo","gpt-35-turbo-16k","gpt-35-turbo-instruct","gpt-4","gpt-4-32k","gpt-4-vision"],"name":"model","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"system_message":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":0.7,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generate text using Azure OpenAI LLMs.","icon":"Azure","base_classes":["object","str","Text"],"display_name":"Azure OpenAI","documentation":"https://python.langchain.com/docs/integrations/llms/azure_openai","custom_fields":{"model":null,"azure_endpoint":null,"input_value":null,"azure_deployment":null,"api_version":null,"api_key":null,"temperature":null,"system_message":null,"max_tokens":null,"stream":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["model","azure_endpoint","azure_deployment","api_version","api_key","temperature","max_tokens","input_value","system_message","stream"],"beta":false},"id":"AzureOpenAIModel-Bbibi"},"selected":false,"width":384,"height":762,"dragging":false,"positionAbsolute":{"x":1226,"y":168.10000610351562}},{"id":"Prompt-FojwL","type":"genericNode","position":{"x":751,"y":196.10000610351562},"data":{"type":"Prompt","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import CustomComponent\nfrom langflow.field_typing import TemplateField\nfrom langflow.field_typing.prompt import Prompt\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    async def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Prompt:\n        prompt = await Prompt.from_template_and_variables(template, kwargs)\n        self.status = prompt.format_text()\n        return prompt\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"prompt","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"System: \n{SystemPrompt}\n\nContext:\n{ChatHistory}\n\nUser:\n{Input}\n\nAI:\n\n","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent","SystemPrompt":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"SystemPrompt","display_name":"SystemPrompt","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"ChatHistory":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"ChatHistory","display_name":"ChatHistory","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"Input":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"Input","display_name":"Input","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Prompt","Record"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["SystemPrompt","ChatHistory","Input"]},"output_types":["Prompt"],"full_path":null,"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"error":null},"id":"Prompt-FojwL","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":607,"positionAbsolute":{"x":751,"y":196.10000610351562},"dragging":false},{"id":"TextInput-nWKIz","type":"genericNode","position":{"x":175,"y":1274.1000061035156},"data":{"type":"TextInput","node":{"template":{"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"Du bist ein freundlicher, kompetenter Assistent, der mich unterstützt. Falls Du eine Frage nicht beantworten kannst, suchst du über bing","fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Record","Text"],"dynamic":false,"info":"Text or Record to be passed as input.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Text\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["object","str","Text"],"display_name":"System Prompt","documentation":"","custom_fields":{"input_value":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"TextInput-nWKIz"},"selected":false,"width":384,"height":297,"positionAbsolute":{"x":175,"y":1274.1000061035156},"dragging":false},{"id":"ChatOutput-sE5pL","type":"genericNode","position":{"x":1729.1991758938298,"y":684.4541415973348},"data":{"type":"ChatOutput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        return_message: Optional[bool] = False,\n    ) -> Union[Message, Text]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            files=files,\n            return_message=return_message,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"return_message":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_message","display_name":"Return Message","advanced":true,"dynamic":false,"info":"Return the message as a Message containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"AI","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":false,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"_type":"CustomComponent"},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message","object","str","Text"],"display_name":"Chat Output","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"files":null,"return_message":null},"output_types":["Message","Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatOutput-sE5pL"},"selected":true,"width":384,"height":391,"positionAbsolute":{"x":1729.1991758938298,"y":684.4541415973348},"dragging":false},{"id":"ChatInput-Onc3G","type":"genericNode","position":{"x":178,"y":798.1000061035156},"data":{"type":"ChatInput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.schema.message import Message\nfrom langflow.field_typing import Text\nfrom typing import Union\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    def build_config(self):\n        build_config = super().build_config()\n        build_config[\"input_value\"] = {\n            \"input_types\": [],\n            \"display_name\": \"Text\",\n            \"multiline\": True,\n        }\n\n        return build_config\n\n    def build(\n        self,\n        sender: Optional[str] = \"User\",\n        sender_name: Optional[str] = \"User\",\n        input_value: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        session_id: Optional[str] = None,\n        return_message: Optional[bool] = False,\n    ) -> Union[Message, Text]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            files=files,\n            session_id=session_id,\n            return_message=return_message,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":[],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"value":"und plus 2 oben drauf`"},"return_message":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_message","display_name":"Return Message","advanced":true,"dynamic":false,"info":"Return the message as a Message containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["Message","object","str","Text"],"display_name":"Chat Input","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"files":null,"session_id":null,"return_message":null},"output_types":["Message","Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatInput-Onc3G"},"selected":false,"width":384,"height":289}],"edges":[{"source":"Prompt-FojwL","sourceHandle":"{œbaseClassesœ:[œPromptœ,œRecordœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-FojwLœ}","target":"AzureOpenAIModel-Bbibi","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œAzureOpenAIModel-Bbibiœ,œinputTypesœ:[œTextœ,œRecordœ,œPromptœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"AzureOpenAIModel-Bbibi","inputTypes":["Text","Record","Prompt"],"type":"str"},"sourceHandle":{"baseClasses":["Prompt","Record"],"dataType":"Prompt","id":"Prompt-FojwL"}},"id":"reactflow__edge-Prompt-FojwL{œbaseClassesœ:[œPromptœ,œRecordœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-FojwLœ}-AzureOpenAIModel-Bbibi{œfieldNameœ:œinput_valueœ,œidœ:œAzureOpenAIModel-Bbibiœ,œinputTypesœ:[œTextœ,œRecordœ,œPromptœ],œtypeœ:œstrœ}"},{"source":"MemoryComponent-SExyL","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œMemoryComponentœ,œidœ:œMemoryComponent-SExyLœ}","target":"Prompt-FojwL","targetHandle":"{œfieldNameœ:œChatHistoryœ,œidœ:œPrompt-FojwLœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"ChatHistory","id":"Prompt-FojwL","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"MemoryComponent","id":"MemoryComponent-SExyL"}},"id":"reactflow__edge-MemoryComponent-SExyL{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œMemoryComponentœ,œidœ:œMemoryComponent-SExyLœ}-Prompt-FojwL{œfieldNameœ:œChatHistoryœ,œidœ:œPrompt-FojwLœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"},{"source":"TextInput-nWKIz","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-nWKIzœ}","target":"Prompt-FojwL","targetHandle":"{œfieldNameœ:œSystemPromptœ,œidœ:œPrompt-FojwLœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"SystemPrompt","id":"Prompt-FojwL","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"TextInput","id":"TextInput-nWKIz"}},"id":"reactflow__edge-TextInput-nWKIz{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-nWKIzœ}-Prompt-FojwL{œfieldNameœ:œSystemPromptœ,œidœ:œPrompt-FojwLœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"},{"source":"AzureOpenAIModel-Bbibi","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-Bbibiœ}","target":"ChatOutput-sE5pL","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-sE5pLœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-sE5pL","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"AzureOpenAIModel","id":"AzureOpenAIModel-Bbibi"}},"id":"reactflow__edge-AzureOpenAIModel-Bbibi{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-Bbibiœ}-ChatOutput-sE5pL{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-sE5pLœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"},{"source":"ChatInput-Onc3G","sourceHandle":"{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-Onc3Gœ}","target":"Prompt-FojwL","targetHandle":"{œfieldNameœ:œInputœ,œidœ:œPrompt-FojwLœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"Input","id":"Prompt-FojwL","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Message","object","str","Text"],"dataType":"ChatInput","id":"ChatInput-Onc3G"}},"id":"reactflow__edge-ChatInput-Onc3G{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-Onc3Gœ}-Prompt-FojwL{œfieldNameœ:œInputœ,œidœ:œPrompt-FojwLœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"}],"viewport":{"x":151.1665814425346,"y":112.03133856456225,"zoom":0.8258776649357199}},"description":"Language Engineering Excellence.","name":"Experiment: LLM mit Websuche","last_tested_version":"1.0.0a52","is_component":false}